# ####ä¸€ã€å¤„ç†æ•°æ®
# import json
# import os
#
# # ğŸ“‚ å®šä¹‰æ–‡ä»¶è·¯å¾„
# input_file = "/data/zhenmengyuan/LLaMA-Factory/data/ko_data/eval_QA.json"
# output_dir = "/data/zhenmengyuan/LLaMA-Factory/saves/task_eval/ko-en/QA/"
# output_file = os.path.join(output_dir, "task_QA.json")
# #demo_output_file = os.path.join(output_dir, "task_SUM_demo.json")  # ç”Ÿæˆ demo æ–‡ä»¶
#
# # ğŸ“‚ ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
# os.makedirs(output_dir, exist_ok=True)
#
# # âœ… è¯»å– eval_SUM.json æ–‡ä»¶
# with open(input_file, "r", encoding="utf-8") as f:
#     eval_data = json.load(f)
#
# # âœ… è½¬æ¢æ ¼å¼
# task_data = []
# for item in eval_data:
#     task_data.append({
#         "instruction": "Please answer the following questions or requests.",
#         "input": item["text_ko"],
#         "output": item["answer_ko"]
#     })
#
# # âœ… ç”Ÿæˆ `task_SUM.json`
# with open(output_file, "w", encoding="utf-8") as f:
#     json.dump(task_data, f, ensure_ascii=False, indent=2)
#
# # ğŸ“¢ æ‰“å°å®Œæˆä¿¡æ¯
# print(f"è½¬æ¢å®Œæˆï¼Œæ–‡ä»¶å·²ä¿å­˜è‡³: {output_file}")



####äºŒã€è°ƒç”¨æ¨¡å‹è¿›è¡Œè¯„ä¼°
import os
import json
import openai
import time
import unicodedata
import re
import torch
from tqdm import tqdm
from rouge import Rouge
from collections import Counter
from openai import OpenAI # å¯¼å…¥OpenAI
from sacrebleu.metrics import BLEU
from mecab import MeCab
from pathlib import Path
from nltk.translate.meteor_score import meteor_score
import nltk
#nltk.download('wordnet')

# æ–‡ä»¶è·¯å¾„
data_file = "task_QA.json"
output_results_file = "gpt_outputs.json"
eval_results_file = "gpt_results.json"

# åŠ è½½æ•°æ®é›†
with open(data_file, "r", encoding="utf-8") as f:
    dataset = json.load(f)

# è¯»å–å·²æœ‰ç»“æœï¼ˆæ”¯æŒæ–­ç‚¹ç»­è·‘ï¼‰
if os.path.exists(output_results_file):
    with open(output_results_file, "r", encoding="utf-8") as f:
        existing_results = json.load(f)
else:
    existing_results = []

# **å»é‡ï¼šè·³è¿‡å·²å¤„ç†çš„æ•°æ®**
processed_inputs = {item["input"] for item in existing_results}
dataset = [item for item in dataset if item["input"] not in processed_inputs]

# âœ… OpenAI API å®¢æˆ·ç«¯ï¼ˆé€‚é…æ–°ç‰ˆ OpenAI SDKï¼‰
client = OpenAI(base_url = "http://chatapi.littlewheat.com/v1",
                api_key  = "sk-RQDnurboWQHgLHqMCvnn7ADAKpJdgPVTluLdL5fr6WM7Habm")
str="(You only need to output the answer, no extra explanation is needed, answer in Korean)"
# **OpenAI API è°ƒç”¨**
def get_gpt4o_response(instruction, input_text, max_retries=3):
    for attempt in range(max_retries):
        messages = [
            {"role": "system", "content": "You are an assistant who is good at answering questions"},
            {"role": "user", "content": f"{instruction}+{str}\n\n{input_text}"}
        ]
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.8,  # ä½æ¸©åº¦ï¼Œä¿è¯ç¨³å®šå›ç­”
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ OpenAI API è°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰ï¼š{e}")
            if attempt == max_retries - 1:
                return "ERROR"
            time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•


# âœ… ä½¿ç”¨mecabè¿›è¡Œåˆ†è¯
# âœ… åˆå§‹åŒ– MeCab
mecab = MeCab(dictionary_path="/data/zhenmengyuan/miniconda3/envs/LLM/lib/mecab/dic/mecab-ko-dic/")
def korean_tokenize(text):
    return " ".join(mecab.morphs(text))
# âœ… è®¡ç®— BLEU
def compute_bleu1(pred: str, gold: str) -> float:
    """åŸºäº SacreBLEU æºç çš„ BLEU è®¡ç®—å‡½æ•° (é€‚é…è—æ–‡åˆ†è¯)"""

    # âœ… åˆå§‹åŒ– BLEU å‚æ•°ï¼ˆä¸æºç é»˜è®¤å‚æ•°å¯¹é½ï¼‰
    bleu = BLEU(
        smooth_method='add-k',  # å¹³æ»‘æ–¹æ³•
        smooth_value=1,  # add-k çš„ k å€¼
        max_ngram_order=4,  # æ˜¾å¼æŒ‡å®š BLEU-4
        effective_order=True,  # ç¦ç”¨åŠ¨æ€ n-gram é˜¶æ•°
        tokenize='ko-mecab',  # ç¦ç”¨å†…ç½®åˆ†è¯ï¼ˆå·²æ‰‹åŠ¨åˆ†è¯ï¼‰
        lowercase=False  # ä¸è½¬å°å†™
    )

    # âœ… è°ƒç”¨ sentence_scoreï¼ˆå‚è€ƒ SacreBLEU æºç é€»è¾‘ï¼‰
    # æ³¨æ„ï¼šreferences å¿…é¡»æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªå‚è€ƒ
    bleu_score = bleu.sentence_score(pred, [gold])

    return bleu_score.score

def compute_bleu2(pred: str, gold: str) -> float:
    """åŸºäº SacreBLEU æºç çš„ BLEU è®¡ç®—å‡½æ•° (é€‚é…è—æ–‡åˆ†è¯)"""

    # âœ… åˆå§‹åŒ– BLEU å‚æ•°ï¼ˆä¸æºç é»˜è®¤å‚æ•°å¯¹é½ï¼‰
    bleu = BLEU(
        smooth_method='add-k',  # å¹³æ»‘æ–¹æ³•
        smooth_value=1,  # add-k çš„ k å€¼
        max_ngram_order=4,  # æ˜¾å¼æŒ‡å®š BLEU-4
        effective_order=True,  # ç¦ç”¨åŠ¨æ€ n-gram é˜¶æ•°
        tokenize='none',  # ç¦ç”¨å†…ç½®åˆ†è¯ï¼ˆå·²æ‰‹åŠ¨åˆ†è¯ï¼‰
        lowercase=False  # ä¸è½¬å°å†™
    )
    pred_tok=korean_tokenize(pred)
    gold_tok=korean_tokenize(gold)

    # âœ… è°ƒç”¨ sentence_scoreï¼ˆå‚è€ƒ SacreBLEU æºç é€»è¾‘ï¼‰
    # æ³¨æ„ï¼šreferences å¿…é¡»æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªå‚è€ƒ
    bleu_score = bleu.sentence_score(pred_tok, [gold_tok])

    return bleu_score.score
# âœ… è®¡ç®— ROUGE
rouge_evaluator = Rouge()
def compute_rouge(pred, gold):
    # ç©ºå€¼è¿‡æ»¤
    pred = __builtins__.str(pred).strip() or " "
    gold = __builtins__.str(gold).strip() or " "

    pred_clean = korean_tokenize(pred)#éœ€è¦åˆ†è¯
    gold_clean = korean_tokenize(gold)
    # äºŒæ¬¡éªŒè¯
    if not pred_clean.strip() or not gold_clean.strip():
        return {
            "rouge-1": {"f": 0.0},
            "rouge-2": {"f": 0.0},
            "rouge-l": {"f": 0.0}
        }

    try:
        scores = rouge_evaluator.get_scores(pred_clean, gold_clean)
        return scores[0]
    except Exception as e:
        print(f"âš ï¸ ROUGE è®¡ç®—å¤±è´¥: pred='{pred_clean}' gold='{gold_clean}'")
        return {
            "rouge-1": {"f": 0.0},
            "rouge-2": {"f": 0.0},
            "rouge-l": {"f": 0.0}
        }


def compute_meteor(pred: str, gold: str) -> float:
    # ä½¿ç”¨ mecab è¿›è¡ŒéŸ©è¯­åˆ†è¯
    pred_tokens = mecab.morphs(pred)
    gold_tokens = mecab.morphs(gold)

    # è®¡ç®— METEOR åˆ†æ•°
    score = meteor_score([gold_tokens], pred_tokens)
    return score

# ğŸš€ **è¿è¡Œæ¨¡å‹ & è¯„ä¼°**
results = existing_results  # åŠ è½½å·²å®Œæˆçš„ç»“æœ
eval_scores = []

# **è¿›åº¦æ¡**
for i, item in enumerate(tqdm(dataset, desc="ğŸš€ å¤„ç†æ•°æ®", unit="æ¡")):
    instruction = item["instruction"]
    input_text = item["input"]
    gold_answer = item["output"]

    # **è°ƒç”¨ GPT-4o ç”Ÿæˆç­”æ¡ˆ**
    model_output = get_gpt4o_response(instruction, input_text)

    # **è®¡ç®—è¯„ä¼°æŒ‡æ ‡**
    rouge_scores = compute_rouge(model_output, gold_answer)
    bleu_scores1 = compute_bleu1(model_output, gold_answer)
    bleu_scores2 = compute_bleu2(model_output, gold_answer)
    meteor_score_value = compute_meteor(model_output, gold_answer)



    # **ä¿å­˜ç»“æœ**
    results.append({
        "instruction": instruction,
        "input": input_text,
        "gold_answer": gold_answer,
        "model_output": model_output,
        "rouge-1": rouge_scores["rouge-1"]["f"],
        "rouge-2": rouge_scores["rouge-2"]["f"],
        "rouge-l": rouge_scores["rouge-l"]["f"],
        "bleu1": bleu_scores1,
        "bleu2": bleu_scores2,
        "meteor": meteor_score_value  # æ–°å¢
    })

    eval_scores.append({
        "rouge-1": rouge_scores["rouge-1"]["f"],
        "rouge-2": rouge_scores["rouge-2"]["f"],
        "rouge-l": rouge_scores["rouge-l"]["f"],
        "bleu1": bleu_scores1,
        "bleu2": bleu_scores2,
        "meteor": meteor_score_value  # æ–°å¢
    })

    # **æ¯ 50 æ¡æ•°æ®å®æ—¶ä¿å­˜ä¸€æ¬¡**
    if (i + 1) % 10 == 0 or (i + 1) == len(dataset):
        with open(output_results_file, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=4)
        print(f"âœ… {i+1}/{len(dataset)} æ¡æ•°æ®å·²ä¿å­˜è‡³ {output_results_file}")

# **è®¡ç®—å¹³å‡è¯„ä¼°æŒ‡æ ‡**
eval_scores = [item for item in results if item["model_output"] != "ERROR"]
num_samples = len(eval_scores)
avg_scores = {
    "ROUGE-1": sum(item["rouge-1"] for item in eval_scores) / num_samples,
    "ROUGE-2": sum(item["rouge-2"] for item in eval_scores) / num_samples,
    "ROUGE-L": sum(item["rouge-l"] for item in eval_scores) / num_samples,
    "BLEU1": sum(item["bleu1"] for item in eval_scores) / num_samples,
    "BLEU2": sum(item["bleu2"] for item in eval_scores) / num_samples,
    "METEOR": sum(item["meteor"] for item in eval_scores) / num_samples  # æ–°å¢
}

# **ä¿å­˜è¯„ä¼°ç»“æœ**
with open(eval_results_file, "w", encoding="utf-8") as f:
    json.dump(avg_scores, f, ensure_ascii=False, indent=4)

print(f"ğŸ“Š è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {eval_results_file}")


###ç»Ÿè®¡ä¸­æ–‡è¾“å‡º
# import json
# import re
#
# # åŠ è½½ JSON æ–‡ä»¶
# with open('deepseek_outputs.json', 'r', encoding='utf-8') as f:
#     data = json.load(f)
#
# # ç»Ÿè®¡åŒ…å«ä¸­æ–‡çš„ model_output æ•°æ®æ¡æ•°
# chinese_count = 0
#
# for item in data:
#     model_output = item['model_output']
#     # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡ï¼ˆUnicode èŒƒå›´ \u4e00-\u9fffï¼‰
#     if re.search(r"[\u4e00-\u9fff]", model_output):
#         chinese_count += 1
#         print(model_output)
#
# # æ‰“å°ç»“æœ
# print(f"åŒ…å«ä¸­æ–‡çš„æ•°æ®æ¡æ•°: {chinese_count}")


# import json
# from rouge import Rouge
# from sacrebleu.metrics import BLEU
# import botok
# import re
# from botok import WordTokenizer
# from botok.config import Config
# from pathlib import Path
# from tqdm import tqdm
#
# # ğŸ”„ ä¿®æ”¹è¾“å‡ºæ–‡ä»¶è·¯å¾„
# #output_results_file = "deepseek_outputs2.json"  # æ–°å¢è¾“å‡ºæ–‡ä»¶
# eval_results_file = "LCTW-deepseek_results2.json"  # æ–°å¢è¯„ä¼°æ–‡ä»¶
# #
# # # âœ… ä½¿ç”¨botokè¿›è¡Œåˆ†è¯
# # config = Config(dialect_name="general", base_path=Path.home())
# # tokenizer = WordTokenizer(config=config)
# #
# #
# # def segment_tibetan_text(text):
# #     """ä½¿ç”¨ Botok è¿›è¡Œè—æ–‡åˆ†è¯"""
# #     tokens = tokenizer.tokenize(text, split_affixes=False)
# #     return " ".join([token.text for token in tokens])
# #
# #
# # def tibetan_syllable_segment(text):
# #     """ä½¿ç”¨è—è¯­éŸ³èŠ‚ç¬¦à¼‹è¿›è¡Œåˆ†è¯"""
# #     # åœ¨æ¯ä¸ªéŸ³èŠ‚ç¬¦åæ·»åŠ ç©ºæ ¼ï¼Œåˆå¹¶å¤šä½™ç©ºæ ¼ï¼Œå¹¶å»é™¤é¦–å°¾ç©ºæ ¼
# #     segmented = text.replace('à¼‹', 'à¼‹ ')
# #     segmented = re.sub(r' +', ' ', segmented)  # åˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼
# #     return segmented.strip()
# #
# # # âœ… è®¡ç®— BLEU
# # def compute_bleu1(pred: str, gold: str) -> float:
# #     """åŸºäº SacreBLEU æºç çš„ BLEU è®¡ç®—å‡½æ•° (é€‚é…è—æ–‡åˆ†è¯)"""
# #
# #     # âœ… åˆå§‹åŒ– BLEU å‚æ•°ï¼ˆä¸æºç é»˜è®¤å‚æ•°å¯¹é½ï¼‰
# #     bleu = BLEU(
# #         smooth_method='add-k',  # å¹³æ»‘æ–¹æ³•
# #         smooth_value=1,  # add-k çš„ k å€¼
# #         max_ngram_order=4,  # æ˜¾å¼æŒ‡å®š BLEU-4
# #         effective_order=True,  # ç¦ç”¨åŠ¨æ€ n-gram é˜¶æ•°
# #         tokenize='none',  # ç¦ç”¨å†…ç½®åˆ†è¯ï¼ˆå·²æ‰‹åŠ¨åˆ†è¯ï¼‰
# #         lowercase=False  # ä¸è½¬å°å†™
# #     )
# #
# #     # âœ… è—æ–‡åˆ†è¯ï¼ˆå‡è®¾ tibetan_syllable_segment å·²æ­£ç¡®å®šä¹‰ï¼‰
# #     pred_tok = segment_tibetan_text(pred)
# #     gold_tok = segment_tibetan_text(gold)
# #
# #     # âœ… è°ƒç”¨ sentence_scoreï¼ˆå‚è€ƒ SacreBLEU æºç é€»è¾‘ï¼‰
# #     # æ³¨æ„ï¼šreferences å¿…é¡»æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªå‚è€ƒ
# #     bleu_score = bleu.sentence_score(pred_tok, [gold_tok])
# #
# #     return bleu_score.score
# #
# # # âœ… è®¡ç®— BLEU
# # def compute_bleu2(pred: str, gold: str) -> float:
# #     """åŸºäº SacreBLEU æºç çš„ BLEU è®¡ç®—å‡½æ•° (é€‚é…è—æ–‡åˆ†è¯)"""
# #
# #     # âœ… åˆå§‹åŒ– BLEU å‚æ•°ï¼ˆä¸æºç é»˜è®¤å‚æ•°å¯¹é½ï¼‰
# #     bleu = BLEU(
# #         smooth_method='add-k',  # å¹³æ»‘æ–¹æ³•
# #         smooth_value=1,  # add-k çš„ k å€¼
# #         max_ngram_order=4,  # æ˜¾å¼æŒ‡å®š BLEU-4
# #         effective_order=True,  # ç¦ç”¨åŠ¨æ€ n-gram é˜¶æ•°
# #         tokenize='none',  # ç¦ç”¨å†…ç½®åˆ†è¯ï¼ˆå·²æ‰‹åŠ¨åˆ†è¯ï¼‰
# #         lowercase=False  # ä¸è½¬å°å†™
# #     )
# #
# #     # âœ… è—æ–‡åˆ†è¯ï¼ˆå‡è®¾ tibetan_syllable_segment å·²æ­£ç¡®å®šä¹‰ï¼‰
# #     pred_tok = tibetan_syllable_segment(pred)
# #     gold_tok = tibetan_syllable_segment(gold)
# #
# #     # âœ… è°ƒç”¨ sentence_scoreï¼ˆå‚è€ƒ SacreBLEU æºç é€»è¾‘ï¼‰
# #     # æ³¨æ„ï¼šreferences å¿…é¡»æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªå‚è€ƒ
# #     bleu_score = bleu.sentence_score(pred_tok, [gold_tok])
# #
# #     return bleu_score.score
# #
# #
# # # âœ… è®¡ç®— ROUGEï¼ˆä¿æŒä¸å˜ï¼‰
# # rouge_evaluator = Rouge()
# #
# # def compute_rouge(pred, gold):
# #     pred = __builtins__.str(pred).strip() or " "
# #     gold = __builtins__.str(gold).strip() or " "
# #
# #     pred_clean = segment_tibetan_text(pred)
# #     gold_clean = segment_tibetan_text(gold)
# #
# #     if not pred_clean.strip() or not gold_clean.strip():
# #         return {"rouge-1": {"f": 0.0}, "rouge-2": {"f": 0.0}, "rouge-l": {"f": 0.0}}
# #
# #     try:
# #         return rouge_evaluator.get_scores(pred_clean, gold_clean)[0]
# #     except Exception as e:
# #         print(f"âš ï¸ ROUGE è®¡ç®—å¤±è´¥: pred='{pred_clean}' gold='{gold_clean}'")
# #         return {"rouge-1": {"f": 0.0}, "rouge-2": {"f": 0.0}, "rouge-l": {"f": 0.0}}
# #
# #
# # # ğŸš€ åŠ è½½åŸå§‹ç»“æœï¼ˆä¸ä¿®æ”¹åŸæ–‡ä»¶ï¼‰
# # with open("deepseek_outputs.json", "r", encoding="utf-8") as f:  # è¯»å–åŸå§‹æ–‡ä»¶
# #     original_results = json.load(f)
# #
# # # åˆ›å»ºæ–°ç»“æœå‰¯æœ¬ï¼ˆé¿å…ä¿®æ”¹åŸå§‹æ•°æ®ï¼‰
# # new_results = [item.copy() for item in original_results]
# #
# # # ğŸ”„ é‡æ–°è®¡ç®—æŒ‡æ ‡
# # print("ğŸ”„ å¼€å§‹é‡æ–°è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
# # for item in tqdm(new_results, desc="ğŸ“Š è¯„ä¼°è¿›åº¦"):
# #     if item.get("model_output") == "ERROR":
# #         continue  # è·³è¿‡é”™è¯¯æ ·æœ¬
# #
# #     # é‡æ–°è®¡ç®—æŒ‡æ ‡
# #     rouge_scores = compute_rouge(item["model_output"], item["gold_answer"])
# #     bleu_scores1 = compute_bleu1(item["model_output"], item["gold_answer"])
# #     bleu_scores2 = compute_bleu2(item["model_output"], item["gold_answer"])
# #
# #     # æ›´æ–°åˆ°æ–°ç»“æœ
# #     item.update({
# #         "rouge-1": rouge_scores["rouge-1"]["f"],
# #         "rouge-2": rouge_scores["rouge-2"]["f"],
# #         "rouge-l": rouge_scores["rouge-l"]["f"],
# #         "bleu1": bleu_scores1,
# #         "bleu2": bleu_scores2
# #     })
# #
# # # ğŸ’¾ ä¿å­˜æ–°è¾“å‡ºæ–‡ä»¶
# # with open(output_results_file, "w", encoding="utf-8") as f:
# #     json.dump(new_results, f, ensure_ascii=False, indent=4)
# # print(f"âœ… æ–°è¾“å‡ºå·²ä¿å­˜è‡³: {output_results_file}")
#
# # ğŸš€ åŠ è½½åŸå§‹ç»“æœï¼ˆä¸ä¿®æ”¹åŸæ–‡ä»¶ï¼‰
# with open("LCTW-deepseek_outputs.json", "r", encoding="utf-8") as f:  # è¯»å–åŸå§‹æ–‡ä»¶
#     new_results = json.load(f)
# # ğŸ“ˆ è®¡ç®—å¹³å‡æŒ‡æ ‡
# valid_items = [item for item in new_results if item.get("model_output") != "ERROR"]
# avg_scores = {
#     "ROUGE-1": sum(i["rouge-1"] for i in valid_items) / len(valid_items),
#     "ROUGE-2": sum(i["rouge-2"] for i in valid_items) / len(valid_items),
#     "ROUGE-L": sum(i["rouge-l"] for i in valid_items) / len(valid_items),
#     "bleu1": sum(i["bleu1"] for i in valid_items) / len(valid_items),
#     "bleu2": sum(i["bleu2"] for i in valid_items) / len(valid_items)
# }
#
# # ğŸ’¾ ä¿å­˜æ–°è¯„ä¼°ç»“æœ
# with open(eval_results_file, "w", encoding="utf-8") as f:
#     json.dump(avg_scores, f, ensure_ascii=False, indent=4)
# print(f"âœ… æ–°è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {eval_results_file}")
#
# # ğŸ“Š æ‰“å°ç»“æœ
# print("\nğŸ“Š æœ€ç»ˆå¹³å‡æŒ‡æ ‡ï¼š")
# print(json.dumps(avg_scores, indent=4, ensure_ascii=False))